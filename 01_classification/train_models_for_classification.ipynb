{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "sys.path.insert(0, \"../pycode\")\n",
    "from models import *\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"max_rows\", 10)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from seaborn import set_style\n",
    "set_style(\"darkgrid\")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_dataset_df(df_robust, app2metric_dd):\n",
    "    set1 = set(df_robust['appName'])\n",
    "    set2 = set(app2metric_dd.keys())\n",
    "    if set1 == set2: print \"Great! appName(s) are identical!\"\n",
    "        \n",
    "    #\n",
    "    # generate an empty dataframe\n",
    "    #\n",
    "    app_pd_series = app2metric_dd[list(app2metric_dd.keys())[0]] # query the 1st key value\n",
    "    feat_cols = list(app_pd_series.index)\n",
    "\n",
    "    feat_cols.insert(0, 'appName')  # add appName to the beginning of the list\n",
    "    feat_cols.insert(len(feat_cols), 'Robust')\n",
    "\n",
    "    appNum = len(app2metric_dd.keys())\n",
    "    df_feat = pd.DataFrame(index=np.arange(0, appNum), columns=feat_cols)\n",
    "\n",
    "    #\n",
    "    # fill in the data\n",
    "    #\n",
    "    \n",
    "    feat_cols = list(app_pd_series.index)\n",
    "\n",
    "    for idx, row in df_feat.iterrows():\n",
    "        appName, robust = df_robust.loc[idx]['appName'], df_robust.loc[idx]['Robust']\n",
    "        metric_list = app2metric_dd[appName]\n",
    "\n",
    "        # update \n",
    "        df_feat.loc[idx, 'appName'] = appName\n",
    "        df_feat.loc[idx, 'Robust'] = robust\n",
    "\n",
    "        # update other metrics\n",
    "        for metric in feat_cols:\n",
    "            df_feat.loc[idx, metric] = metric_list[metric]\n",
    "            \n",
    "    return df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def gen_model_input(df_dataset):\n",
    "#     np_data = df_dataset.values  # convert df to array\n",
    "#     np_data_clean = np.delete(np_data, np.s_[0], axis=1) # remove 1st column = appName\n",
    "\n",
    "#     ColNum = np_data_clean.shape[1]  # number of columns\n",
    "#     np_X = np_data_clean[:,[i for i in xrange(0,ColNum-1)]]  # select data except the last col\n",
    "#     np_y = np_data_clean[:,[-1]]  # select the last column (as the label)\n",
    "\n",
    "#     return np_X, np_y\n",
    "\n",
    "\n",
    "def gen_model_input(df_dataset):\n",
    "    df_X = df_dataset.drop(['appName', 'Robust'], axis=1)\n",
    "    df_y = df_dataset['Robust']\n",
    "    df_y = df_y.astype('int64')  # convert obj to int\n",
    "    return df_X, df_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GreedySearch(df_X, df_y, fold_k = 3):\n",
    "    modelErrorList = []\n",
    "    \n",
    "    # decision tree\n",
    "    dt_tree_error, dt_tree_params = GreedySearch_dtree(df_X, df_y, fold_k=fold_k)\n",
    "    print dt_tree_error, dt_tree_params\n",
    "    modelErrorList.append((dt_tree_error, 'dtree', dt_tree_params))\n",
    "    \n",
    "    # knn\n",
    "    knn_error, knn_params = GreedySearch_KNN(df_X, df_y, fold_k=fold_k)\n",
    "    print knn_error, knn_params\n",
    "    modelErrorList.append((knn_error, 'knn', knn_params))\n",
    "\n",
    "    # svm\n",
    "    svc_error, svc_params = GreedySearch_SVC(df_X, df_y, fold_k=fold_k)\n",
    "    print svc_error, svc_params\n",
    "    modelErrorList.append((svc_error, 'svc', svc_params))\n",
    "\n",
    "    # random forest\n",
    "    rf_error, rf_params = GreedySearch_RandomForest(df_X, df_y, fold_k=fold_k)\n",
    "    print rf_error, rf_params\n",
    "    modelErrorList.append((rf_error, 'random forest', rf_params))\n",
    "\n",
    "    nn_error, nn_params = GreedySearch_MLP(df_X, df_y, fold_k=fold_k)\n",
    "    print nn_error, nn_params\n",
    "    modelErrorList.append((nn_error, 'neural nets', nn_params))\n",
    "\n",
    "    ada_error, ada_params = GreedySearch_AdaBoost(df_X, df_y, fold_k=fold_k)\n",
    "    print ada_error, ada_params\n",
    "    modelErrorList.append((ada_error, 'AdaBoost', ada_params))\n",
    "\n",
    "    nb_error = GreedySearch_GaussianNB(df_X, df_y, fold_k=fold_k)\n",
    "    print nb_error\n",
    "    modelErrorList.append((nb_error, 'GaussianNB', \"\"))\n",
    "\n",
    "    qda_error = GreedySearch_QDA(df_X, df_y, fold_k=fold_k)\n",
    "    print qda_error\n",
    "    modelErrorList.append((qda_error, 'QDA', \"\"))\n",
    "    \n",
    "    sort_model_by_error = sorted(modelErrorList, key=lambda x: x[0]) #  error is the 1st value\n",
    "    \n",
    "    # output\n",
    "    return sort_model_by_error[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df_robust = pd.read_csv('../prepare/run2/app_classify.csv')\n",
    "print type(df_robust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# featall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app2metric_featall = np.load('../prepare/app2metric_featAll.npy').item()\n",
    "# df_dataset = gen_dataset_df(df_robust, app2metric_featall)\n",
    "# df_dataset.to_csv(\"dataset_using_featall.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "# print df_dataset.groupby(\"Robust\").size()\n",
    "\n",
    "# df_X, df_y = gen_model_input(df_dataset)\n",
    "\n",
    "# # Test different models, find the best\n",
    "# [error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k=3)\n",
    "# print bestModel, error, modelParam\n",
    "\n",
    "# # Test different models, find the best\n",
    "# [error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k=5)\n",
    "# print bestModel, error, modelParam\n",
    "\n",
    "# # Test different models, find the best\n",
    "# [error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k=10)\n",
    "# print bestModel, error, modelParam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feat64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app2metric_feat = np.load('../prepare/app2metric_feat64.npy').item()\n",
    "# df_dataset = gen_dataset_df(df_robust, app2metric_feat)\n",
    "# df_dataset.to_csv(\"dataset_using_feat64.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "# print df_dataset.groupby(\"Robust\").size()\n",
    "\n",
    "# df_X, df_y = gen_model_input(df_dataset)\n",
    "\n",
    "# # Test different models, find the best\n",
    "# [error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 3)\n",
    "# print bestModel, error, modelParam\n",
    "\n",
    "# # Test different models, find the best\n",
    "# [error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 5)\n",
    "# print bestModel, error, modelParam\n",
    "\n",
    "# # Test different models, find the best\n",
    "# [error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 10)\n",
    "# print bestModel, error, modelParam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feat42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app2metric_feat = np.load('../prepare/app2metric_feat42.npy').item()\n",
    "# df_dataset = gen_dataset_df(df_robust, app2metric_feat)\n",
    "# df_dataset.to_csv(\"dataset_using_feat42.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "# print df_dataset.groupby(\"Robust\").size()\n",
    "\n",
    "# df_X, df_y = gen_model_input(df_dataset)\n",
    "\n",
    "# # Test different models, find the best\n",
    "# [error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 3)\n",
    "# print bestModel, error, modelParam\n",
    "\n",
    "# # Test different models, find the best\n",
    "# [error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 5)\n",
    "# print bestModel, error, modelParam\n",
    "\n",
    "# # Test different models, find the best\n",
    "# [error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 10)\n",
    "# print bestModel, error, modelParam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feat26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app2metric_feat = np.load('../prepare/app2metric_feat26.npy').item()\n",
    "# df_dataset = gen_dataset_df(df_robust, app2metric_feat)\n",
    "# df_dataset.to_csv(\"dataset_using_feat26.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "# print df_dataset.groupby(\"Robust\").size()\n",
    "\n",
    "# df_X, df_y = gen_model_input(df_dataset)\n",
    "\n",
    "# # Test different models, find the best\n",
    "# [error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 3)\n",
    "# print bestModel, error, modelParam\n",
    "\n",
    "# # Test different models, find the best\n",
    "# [error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 5)\n",
    "# print bestModel, error, modelParam\n",
    "\n",
    "# # Test different models, find the best\n",
    "# [error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 10)\n",
    "# print bestModel, error, modelParam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feat18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app2metric_feat = np.load('../prepare/app2metric_feat18.npy').item()\n",
    "# df_dataset = gen_dataset_df(df_robust, app2metric_feat)\n",
    "# df_dataset.to_csv(\"dataset_using_feat18.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "# print df_dataset.groupby(\"Robust\").size()\n",
    "\n",
    "# df_X, df_y = gen_model_input(df_dataset)\n",
    "\n",
    "# # Test different models, find the best\n",
    "# [error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 3)\n",
    "# print bestModel, error, modelParam\n",
    "\n",
    "# # Test different models, find the best\n",
    "# [error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 5)\n",
    "# print bestModel, error, modelParam\n",
    "\n",
    "# # Test different models, find the best\n",
    "# [error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 10)\n",
    "# print bestModel, error, modelParam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feat14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! appName(s) are identical!\n",
      "0.32790123456790127 {'criterion': 'entropy', 'max_depth': 2}\n",
      "0.2908641975308642 {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'brute', 'p': 2}\n",
      "0.32888888888888884 {'kernel': 'sigmoid', 'C': 0.025, 'degree': 6}\n",
      "0.30320987654320986 {'n_estimators': 10, 'max_features': 'log2', 'criterion': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leiming/anaconda2/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30419753086419754 {'alpha': 0.1, 'activation': 'relu', 'solver': 'sgd', 'hidden_layer_sizes': (30, 30, 30)}\n",
      "0.32888888888888884 {'n_estimators': 30, 'learning_rate': 1.0}\n",
      "0.46469135802469136\n",
      "0.425679012345679\n",
      "knn 0.2908641975308642 {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'brute', 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leiming/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/leiming/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:719: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/leiming/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:719: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/leiming/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:722: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3813235294117647 {'criterion': 'gini', 'max_depth': 2}\n",
      "0.24975490196078431 {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'p': 2}\n",
      "0.328921568627451 {'kernel': 'sigmoid', 'C': 0.025, 'degree': 6}\n",
      "0.26705882352941174 {'n_estimators': 50, 'max_features': 'auto', 'criterion': 'entropy'}\n",
      "0.276421568627451 {'alpha': 0.001, 'activation': 'tanh', 'solver': 'sgd', 'hidden_layer_sizes': (30, 30, 30)}\n",
      "0.2787254901960784 {'n_estimators': 60, 'learning_rate': 0.1}\n",
      "0.42671568627450973\n",
      "0.31088235294117644\n",
      "knn 0.24975490196078431 {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'p': 2}\n",
      "0.31726190476190474 {'criterion': 'entropy', 'max_depth': 2}\n",
      "0.21488095238095237 {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute', 'p': 1}\n",
      "0.28849206349206347 {'kernel': 'linear', 'C': 1.0, 'degree': 6}\n",
      "0.23988095238095236 {'n_estimators': 10, 'max_features': 'log2', 'criterion': 'gini'}\n",
      "0.2871031746031746 {'alpha': 0.1, 'activation': 'tanh', 'solver': 'sgd', 'hidden_layer_sizes': (60, 60, 60)}\n",
      "0.31607142857142856 {'n_estimators': 10, 'learning_rate': 1.0}\n",
      "0.4095238095238095\n",
      "0.3823412698412698\n",
      "knn 0.21488095238095237 {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute', 'p': 1}\n"
     ]
    }
   ],
   "source": [
    "app2metric_feat = np.load('../prepare/app2metric_feat14.npy').item()\n",
    "df_dataset = gen_dataset_df(df_robust, app2metric_feat)\n",
    "df_dataset.to_csv(\"dataset_using_feat14.csv\", index=False, encoding='utf-8')\n",
    "#print df_dataset.groupby(\"Robust\").size()\n",
    "\n",
    "df_X, df_y = gen_model_input(df_dataset)\n",
    "\n",
    "# Test different models, find the best\n",
    "[error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 3)\n",
    "print bestModel, error, modelParam\n",
    "\n",
    "# Test different models, find the best\n",
    "[error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 5)\n",
    "print bestModel, error, modelParam\n",
    "\n",
    "# Test different models, find the best\n",
    "[error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 10)\n",
    "print bestModel, error, modelParam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feat12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! appName(s) are identical!\n",
      "0.3071604938271605 {'criterion': 'entropy', 'max_depth': 6}\n",
      "0.32888888888888884 {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'p': 1}\n",
      "0.32888888888888884 {'kernel': 'sigmoid', 'C': 0.025, 'degree': 6}\n",
      "0.30518518518518517 {'n_estimators': 50, 'max_features': 'auto', 'criterion': 'entropy'}\n",
      "0.32888888888888884 {'alpha': 0.001, 'activation': 'relu', 'solver': 'sgd', 'hidden_layer_sizes': (100, 100, 100)}\n",
      "0.3422222222222222 {'n_estimators': 100, 'learning_rate': 0.01}\n",
      "0.5654320987654321\n",
      "0.47901234567901235\n",
      "random forest 0.30518518518518517 {'n_estimators': 50, 'max_features': 'auto', 'criterion': 'entropy'}\n",
      "0.32568627450980386 {'criterion': 'entropy', 'max_depth': 4}\n",
      "0.27558823529411763 {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'p': 1}\n",
      "0.328921568627451 {'kernel': 'sigmoid', 'C': 0.025, 'degree': 6}\n",
      "0.27862745098039216 {'n_estimators': 50, 'max_features': 'log2', 'criterion': 'entropy'}\n",
      "0.28735294117647053 {'alpha': 1.0, 'activation': 'identity', 'solver': 'sgd', 'hidden_layer_sizes': (60, 60, 60)}\n",
      "0.30308823529411766 {'n_estimators': 10, 'learning_rate': 1.0}\n",
      "0.5543137254901962\n",
      "0.4894117647058823\n",
      "knn 0.27558823529411763 {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'p': 1}\n",
      "0.3361111111111111 {'criterion': 'gini', 'max_depth': 8}\n",
      "0.28849206349206347 {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'brute', 'p': 1}\n",
      "0.32678571428571423 {'kernel': 'sigmoid', 'C': 0.025, 'degree': 6}\n",
      "0.2509920634920635 {'n_estimators': 50, 'max_features': 'auto', 'criterion': 'gini'}\n",
      "0.2728174603174603 {'alpha': 1.0, 'activation': 'identity', 'solver': 'sgd', 'hidden_layer_sizes': (100, 100, 100)}\n",
      "0.2571428571428572 {'n_estimators': 60, 'learning_rate': 0.1}\n",
      "0.5517857142857142\n",
      "0.5541666666666667\n",
      "random forest 0.2509920634920635 {'n_estimators': 50, 'max_features': 'auto', 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "app2metric_feat = np.load('../prepare/app2metric_feat12.npy').item()\n",
    "df_dataset = gen_dataset_df(df_robust, app2metric_feat)\n",
    "df_dataset.to_csv(\"dataset_using_feat12.csv\", index=False, encoding='utf-8')\n",
    "#print df_dataset.groupby(\"Robust\").size()\n",
    "\n",
    "df_X, df_y = gen_model_input(df_dataset)\n",
    "\n",
    "# Test different models, find the best\n",
    "[error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 3)\n",
    "print bestModel, error, modelParam\n",
    "\n",
    "# Test different models, find the best\n",
    "[error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 5)\n",
    "print bestModel, error, modelParam\n",
    "\n",
    "# Test different models, find the best\n",
    "[error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 10)\n",
    "print bestModel, error, modelParam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feat9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! appName(s) are identical!\n",
      "0.31555555555555553 {'criterion': 'gini', 'max_depth': 3}\n",
      "0.30123456790123454 {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'p': 1}\n",
      "0.32888888888888884 {'kernel': 'sigmoid', 'C': 0.025, 'degree': 6}\n",
      "0.30419753086419754 {'n_estimators': 50, 'max_features': 'log2', 'criterion': 'entropy'}\n",
      "0.2898765432098765 {'alpha': 1.0, 'activation': 'identity', 'solver': 'sgd', 'hidden_layer_sizes': (30, 30, 30)}\n",
      "0.3298765432098765 {'n_estimators': 100, 'learning_rate': 0.01}\n",
      "0.5293827160493827\n",
      "0.3916049382716049\n",
      "neural nets 0.2898765432098765 {'alpha': 1.0, 'activation': 'identity', 'solver': 'sgd', 'hidden_layer_sizes': (30, 30, 30)}\n",
      "0.29049019607843135 {'criterion': 'entropy', 'max_depth': 4}\n",
      "0.23715686274509803 {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'p': 1}\n",
      "0.328921568627451 {'kernel': 'sigmoid', 'C': 0.025, 'degree': 6}\n",
      "0.2927941176470588 {'n_estimators': 50, 'max_features': 'auto', 'criterion': 'gini'}\n",
      "0.26465686274509803 {'alpha': 1.0, 'activation': 'tanh', 'solver': 'sgd', 'hidden_layer_sizes': (30, 30, 30)}\n",
      "0.27862745098039216 {'n_estimators': 30, 'learning_rate': 0.1}\n",
      "0.4909803921568628\n",
      "0.4542156862745098\n",
      "knn 0.23715686274509803 {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'p': 1}\n",
      "0.3569444444444444 {'criterion': 'gini', 'max_depth': 4}\n",
      "0.2442460317460317 {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'brute', 'p': 2}\n",
      "0.32678571428571423 {'kernel': 'sigmoid', 'C': 0.025, 'degree': 6}\n",
      "0.2648809523809524 {'n_estimators': 50, 'max_features': 'auto', 'criterion': 'entropy'}\n",
      "0.258531746031746 {'alpha': 1.0, 'activation': 'identity', 'solver': 'sgd', 'hidden_layer_sizes': (100, 100, 100)}\n",
      "0.2968253968253968 {'n_estimators': 60, 'learning_rate': 0.1}\n",
      "0.5182539682539683\n",
      "0.43769841269841264\n",
      "knn 0.2442460317460317 {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'brute', 'p': 2}\n"
     ]
    }
   ],
   "source": [
    "app2metric_feat = np.load('../prepare/app2metric_feat9.npy').item()\n",
    "df_dataset = gen_dataset_df(df_robust, app2metric_feat)\n",
    "df_dataset.to_csv(\"dataset_using_feat9.csv\", index=False, encoding='utf-8')\n",
    "#print df_dataset.groupby(\"Robust\").size()\n",
    "\n",
    "df_X, df_y = gen_model_input(df_dataset)\n",
    "\n",
    "# Test different models, find the best\n",
    "[error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 3)\n",
    "print bestModel, error, modelParam\n",
    "\n",
    "# Test different models, find the best\n",
    "[error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 5)\n",
    "print bestModel, error, modelParam\n",
    "\n",
    "# Test different models, find the best\n",
    "[error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 10)\n",
    "print bestModel, error, modelParam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# featMystic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! appName(s) are identical!\n",
      "0.22518518518518518 {'criterion': 'gini', 'max_depth': 10}\n",
      "0.2765432098765432 {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'p': 2}\n",
      "0.2908641975308642 {'kernel': 'poly', 'C': 0.025, 'degree': 6}\n",
      "0.3298765432098765 {'n_estimators': 50, 'max_features': 'log2', 'criterion': 'entropy'}\n",
      "0.27851851851851855 {'alpha': 0.01, 'activation': 'identity', 'solver': 'adam', 'hidden_layer_sizes': (100, 100, 100)}\n",
      "0.18814814814814815 {'n_estimators': 30, 'learning_rate': 0.01}\n",
      "0.30617283950617286\n",
      "0.32888888888888884\n",
      "AdaBoost 0.18814814814814815 {'n_estimators': 30, 'learning_rate': 0.01}\n",
      "0.20112745098039214 {'criterion': 'entropy', 'max_depth': 7}\n",
      "0.2403921568627451 {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'p': 2}\n",
      "0.2897549019607843 {'kernel': 'poly', 'C': 0.025, 'degree': 6}\n",
      "0.18779411764705883 {'n_estimators': 100, 'max_features': 'log2', 'criterion': 'gini'}\n",
      "0.2403921568627451 {'alpha': 0.001, 'activation': 'tanh', 'solver': 'sgd', 'hidden_layer_sizes': (30, 30, 30)}\n",
      "0.22475490196078432 {'n_estimators': 60, 'learning_rate': 0.1}\n",
      "0.2788235294117647\n",
      "0.25289215686274513\n",
      "random forest 0.18779411764705883 {'n_estimators': 100, 'max_features': 'log2', 'criterion': 'gini'}\n",
      "0.2650793650793651 {'criterion': 'gini', 'max_depth': 6}\n",
      "0.22380952380952376 {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'p': 2}\n",
      "0.2875 {'kernel': 'poly', 'C': 0.025, 'degree': 6}\n",
      "0.2123015873015873 {'n_estimators': 50, 'max_features': 'log2', 'criterion': 'entropy'}\n",
      "0.2509920634920635 {'alpha': 0.1, 'activation': 'tanh', 'solver': 'sgd', 'hidden_layer_sizes': (60, 60, 60)}\n",
      "0.23769841269841266 {'n_estimators': 60, 'learning_rate': 0.01}\n",
      "0.27817460317460313\n",
      "0.27599206349206346\n",
      "random forest 0.2123015873015873 {'n_estimators': 50, 'max_features': 'log2', 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "app2metric_feat = np.load('../prepare/app2metric_featMystic.npy').item()\n",
    "df_dataset = gen_dataset_df(df_robust, app2metric_feat)\n",
    "df_dataset.to_csv(\"dataset_using_featMystic.csv\", index=False, encoding='utf-8')\n",
    "#print df_dataset.groupby(\"Robust\").size()\n",
    "\n",
    "df_X, df_y = gen_model_input(df_dataset)\n",
    "\n",
    "# Test different models, find the best\n",
    "[error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 3)\n",
    "print bestModel, error, modelParam\n",
    "\n",
    "# Test different models, find the best\n",
    "[error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 5)\n",
    "print bestModel, error, modelParam\n",
    "\n",
    "# Test different models, find the best\n",
    "[error, bestModel, modelParam] = GreedySearch(df_X, df_y, fold_k = 10)\n",
    "print bestModel, error, modelParam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
